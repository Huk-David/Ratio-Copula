{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import scipy.stats as scs\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.distributions as dist\n",
    "from pyhmc import hmc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ot\\backend.py:2998: UserWarning: To use TensorflowBackend, you need to activate the tensorflow numpy API. You can activate it by running: \n",
      "from tensorflow.python.ops.numpy_ops import np_config\n",
      "np_config.enable_numpy_behavior()\n",
      "  register_backend(TensorflowBackend())\n"
     ]
    }
   ],
   "source": [
    "import ot\n",
    "def W2(x,y):\n",
    "    return torch.sqrt(ot.emd2(torch.ones(x.shape[0])/x.shape[0], torch.ones(y.shape[0])/y.shape[0], ot.dist(x, y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 359. MiB for an array with shape (47040000,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24172\\2877591314.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[1;31m# load all mnist data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, q, *args, **kwds)\u001b[0m\n\u001b[0;32m   2250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2251\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# call only if at least 1 entry\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2252\u001b[0m             \u001b[0mgoodargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margsreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2253\u001b[0m             \u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgoodargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgoodargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgoodargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgoodargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2254\u001b[1;33m             \u001b[0mplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ppf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgoodargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscale\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2255\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2256\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2257\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\_continuous_distns.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, q)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_ppf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_norm_ppf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\_continuous_distns.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(q)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_norm_ppf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndtri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 359. MiB for an array with shape (47040000,) and data type float64"
     ]
    }
   ],
   "source": [
    "# load all mnist data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "np.random.seed(990109)\n",
    "torch.manual_seed(990109)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Lambda(lambda x: x.view(784))])\n",
    "trainset = datasets.MNIST(root='../MNIST_exp', train=True, download=False, transform=transform)\n",
    "data_true = trainset.data.numpy()\n",
    "data_true = data_true.reshape(data_true.shape[0], -1)\n",
    "\n",
    "# Add Gaussian noise to dequentize\n",
    "noise = scs.norm.rvs(0, 0.05, data_true.shape)\n",
    "X_noisy_flat = (data_true + noise)\n",
    "\n",
    "# Apply ECDF transformation\n",
    "X_ecdf = np.zeros_like(X_noisy_flat)\n",
    "ecdf_list = []\n",
    "for dim in (range(X_noisy_flat.shape[1])):\n",
    "    ecdf = ECDF(X_noisy_flat[:, dim])\n",
    "    ecdf_list.append(ecdf)\n",
    "    X_ecdf[:, dim] = np.clip(ecdf(X_noisy_flat[:, dim]), 1e-6, 1 - 1e-6)\n",
    "\n",
    "\n",
    "\n",
    "# Apply inverse of standard normal CDF (ppf)\n",
    "X_gaussian = scs.norm.ppf(X_ecdf).reshape(-1, 28,28)\n",
    "y_gaussian = torch.ones(X_gaussian.shape[0], dtype=torch.long)\n",
    "# make it a tensor with shape (n_samples, n_channels, height, width)\n",
    "X_gaussian = torch.tensor(X_gaussian, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n",
    "\n",
    "# Split the data into training and testing sets (50/50 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_gaussian, y_gaussian, test_size=0.5, random_state=42)\n",
    "# Create TensorDataset objects\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "# Create DataLoader objects\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.80s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Gauss_LL_mnist = []\n",
    "Gauss_W2_mnist = []\n",
    "for i in tqdm(range(10)):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_gaussian, y_gaussian, test_size=0.5, random_state=i)\n",
    "\n",
    "\n",
    "    gauss_cov = np.cov(X_train.reshape(-1, 784).T)\n",
    "    top = (scs.multivariate_normal.logpdf(X_test.reshape(-1, 784), mean=np.zeros(784), cov=gauss_cov+1e-10*np.eye(784)).mean())\n",
    "    bot = (scs.multivariate_normal.logpdf(X_test.reshape(-1, 784), mean=np.zeros(784), cov=np.eye(784)).mean())\n",
    "    Gauss_LL_mnist.append(top-bot)\n",
    "    sims_gauss = scs.multivariate_normal.rvs(mean=np.zeros(784), cov=gauss_cov+1e-10*np.eye(784), size=25)\n",
    "    Gauss_W2_mnist.append(W2(X_test.reshape(-1,28*28).float(),torch.tensor(sims_gauss).reshape(-1,28*28).float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126.42638961130842, 0.0, 37.04207, 0.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(Gauss_LL_mnist), np.std(Gauss_LL_mnist),np.mean(Gauss_W2_mnist), np.std(Gauss_W2_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "c:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "c:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(198.38777777777779, 19.72151773389652, nan, nan)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GGCNN_LL_mnist = [\n",
    "197.11,\n",
    "203.69,\n",
    "220.88,\n",
    "217.37,\n",
    "164.36,\n",
    "196.70,\n",
    "168.83,\n",
    "194.59,\n",
    "221.96]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "np.mean(GGCNN_LL_mnist), np.std(GGCNN_LL_mnist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IGC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    #### IGC model\n",
    "\n",
    "\n",
    "\n",
    "    class SoftRank(nn.Module):\n",
    "        \"\"\"Differentiable ranking layer\"\"\"\n",
    "        def __init__(self, alpha=1000.0):\n",
    "            super(SoftRank, self).__init__()\n",
    "            self.alpha = alpha # constant for scaling the sigmoid to approximate sign function, larger values ensure better ranking, overflow is handled properly by PyTorch\n",
    "\n",
    "        def forward(self, inputs):\n",
    "            # input is a ?xSxD tensor, we wish to rank the S samples in each dimension per each batch\n",
    "            # output is  ?xSxD tensor where for each dimension the entries are (rank-0.5)/N_rank\n",
    "            x = inputs.unsqueeze(-1) #(?,S,D) -> (?,S,D,1)\n",
    "            x_2 = x.repeat(1, 1, 1, x.shape[1]) # (?,S,D,1) -> (?,S,D,S) (samples are repeated along axis 3, i.e. the last axis)\n",
    "            x_1 = x_2.transpose(1, 3) #  (?,S,D,S) -> (?,S,D,S) (samples are repeated along axis 1)\n",
    "            return torch.transpose(torch.sum(torch.sigmoid(self.alpha*(x_1-x_2)), dim=1), 1, 2)/(torch.tensor(x.shape[1], dtype=torch.float32))\n",
    "\n",
    "\n",
    "    class IGC(nn.Module):\n",
    "        \n",
    "        def __init__(self, hidden_size=100, layers_number=2, output_size=2):\n",
    "            super(IGC, self).__init__()\n",
    "            self.dim_latent = 3 * output_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.layers_nuber = layers_number\n",
    "            self.output_size = output_size\n",
    "            self.linear_in = nn.Linear(in_features=self.dim_latent, out_features=self.hidden_size) \n",
    "            self.linear = nn.Linear(in_features=self.hidden_size, out_features=self.hidden_size)\n",
    "            self.linear_out = nn.Linear(in_features=self.hidden_size, out_features=self.output_size)\n",
    "            self.marginal_cdfs = None\n",
    "            self.ecdf_10e6_samples = None\n",
    "\n",
    "        def forward_train(self, z):\n",
    "            '''\n",
    "            Input noise z with shape (M,dim_latent)\\\\\n",
    "            Outputs (u,v) pairs with shape (M,output_size=2), while ensuring u and v each have uniform marginals.\n",
    "            '''\n",
    "            y = torch.relu(self.linear_in(z))\n",
    "            for layer in range(self.layers_nuber):\n",
    "                y = torch.relu(self.linear(y))\n",
    "            y = self.linear_out(y).unsqueeze(0)\n",
    "            u = SoftRank()(y).squeeze(0)\n",
    "            return u\n",
    "            \n",
    "        def Energy_Score_pytorch(self,beta, observations_y, simulations_Y):\n",
    "            n = len(observations_y)\n",
    "            m = len(simulations_Y)\n",
    "\n",
    "            # First part |Y-y|. Gives the L2 dist scaled by power beta. Is a vector of length n/one value per location.\n",
    "            diff_Y_y = torch.pow(\n",
    "                torch.norm(\n",
    "                    (observations_y.unsqueeze(1) -\n",
    "                    simulations_Y.unsqueeze(0)).float(),\n",
    "                    dim=2,keepdim=True).reshape(-1,1),\n",
    "                beta)\n",
    "\n",
    "            # Second part |Y-Y'|. 2* because pdist counts only once.\n",
    "            diff_Y_Y = 2 * torch.pow(\n",
    "                nn.functional.pdist(simulations_Y),\n",
    "                beta)\n",
    "            Energy = 2 * torch.mean(diff_Y_y) - torch.sum(diff_Y_Y) / (m * (m - 1))\n",
    "            return Energy\n",
    "\n",
    "\n",
    "        def forward(self, n_samples):\n",
    "            ''' \n",
    "            Function to sample from the copula, once training is done.\n",
    "\n",
    "            Input: n_samples - number of samples to generate\n",
    "            Output: torch.tensor of shape (n_samples, output_size) on copula space.\n",
    "            '''\n",
    "            with torch.no_grad():\n",
    "                if self.marginal_cdfs is None:\n",
    "                    self.marginal_cdfs = []\n",
    "                    # sample 10^6 points from the latent space and compute empirical marginal cdfs\n",
    "                    z = torch.randn(10**6, self.dim_latent)\n",
    "                    y = torch.relu(self.linear_in(z))\n",
    "                    for layer in range(self.layers_nuber):\n",
    "                        y = torch.relu(self.linear(y))\n",
    "                    y = self.linear_out(y) # samples used to approximate cdfs\n",
    "                    for dim in range(y.shape[1]):\n",
    "                        ecdf = ECDF(y[:, dim].numpy())\n",
    "                        self.marginal_cdfs.append(ecdf)\n",
    "                    self.ecdf_10e6_samples = y\n",
    "                # sample the latent space and apply ecdfs\n",
    "                z = torch.randn(n_samples, self.dim_latent)\n",
    "                y = torch.relu(self.linear_in(z))\n",
    "                for layer in range(self.layers_nuber):\n",
    "                    y = torch.relu(self.linear(y))\n",
    "                y = self.linear_out(y)\n",
    "                for dim in range(y.shape[1]):\n",
    "                    y[:, dim] = torch.tensor(self.marginal_cdfs[dim](y[:, dim].numpy()), dtype=torch.float32)\n",
    "                return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 324584\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of parameters\n",
    "igc_cop = IGC(hidden_size=100, layers_number=2, output_size=28*28)\n",
    "total_params = sum(p.numel() for p in igc_cop.parameters())\n",
    "print(f'Total parameters: {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/501 [00:01<09:06,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.488859176635742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 101/501 [01:42<07:26,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.326433181762695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 201/501 [03:24<05:14,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.393627166748047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 301/501 [05:05<03:20,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.326325416564941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 401/501 [06:48<01:39,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.47313404083252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [08:28<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.323182106018066\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(36.0503), 'IGC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/501 [00:00<08:18,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.507871627807617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 101/501 [01:39<06:33,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.459611892700195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 201/501 [03:19<04:57,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.34811782836914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 301/501 [04:57<03:16,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.423545837402344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 401/501 [06:40<01:39,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.410325050354004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [08:18<00:00,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.424661636352539\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ot\\lp\\__init__.py:571: UserWarning: numItermax reached before optimality. Try to increase numItermax.\n",
      "  check_result(result_code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(36.1236), 'IGC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/501 [00:00<08:14,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.437948226928711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 101/501 [01:38<06:24,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.46111011505127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 201/501 [03:16<04:53,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.37551212310791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 301/501 [04:54<03:15,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.357294082641602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 401/501 [06:32<01:38,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.389264106750488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [08:10<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.344599723815918\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(35.9470), 'IGC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/501 [00:00<08:05,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.483895301818848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 101/501 [01:38<06:28,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.426070213317871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 201/501 [03:16<04:51,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.443681716918945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 301/501 [04:54<03:16,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.421318054199219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 401/501 [06:32<01:38,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.405848503112793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [08:10<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.38180160522461\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(36.0018), 'IGC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/501 [00:01<08:28,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.376882553100586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 101/501 [01:42<06:41,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.34701156616211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 201/501 [03:20<04:59,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.430047035217285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 301/501 [05:01<03:13,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.390410423278809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 401/501 [06:40<01:43,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.308869361877441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [08:22<00:00,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.437922477722168\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(36.0666), 'IGC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/501 [00:01<08:43,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.512635231018066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 101/501 [01:41<06:30,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.479730606079102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 201/501 [03:19<04:55,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.371349334716797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 301/501 [04:57<03:15,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.517054557800293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 401/501 [06:38<01:36,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.411425590515137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [08:20<00:00,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.41932487487793\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(35.9763), 'IGC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/501 [00:00<08:04,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.436112403869629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 101/501 [01:38<06:27,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.3960542678833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 201/501 [03:17<04:53,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.338504791259766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 301/501 [04:55<03:14,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.333251953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 401/501 [06:32<01:36,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.443769454956055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [08:13<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.38141918182373\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(35.9971), 'IGC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/501 [00:00<08:11,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.414690971374512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 101/501 [01:38<06:32,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.390527725219727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 201/501 [03:20<04:59,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.417322158813477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 301/501 [05:03<03:16,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.38468074798584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 401/501 [06:47<01:36,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.455321311950684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [08:27<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.310917854309082\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(36.0689), 'IGC')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/501 [00:00<08:03,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.508523941040039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 101/501 [01:41<06:29,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.37524127960205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 201/501 [03:22<05:02,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.392394065856934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 301/501 [05:03<03:20,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.346386909484863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 401/501 [06:43<01:37,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.436563491821289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [08:22<00:00,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.369071960449219\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(35.8969), 'IGC')\n"
     ]
    }
   ],
   "source": [
    "for seed in range(10):\n",
    "    # Split the data into training and testing sets (50/50 split)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_gaussian, y_gaussian, test_size=0.5, random_state=seed)\n",
    "    # make training data on 0-1 scale\n",
    "    X_train_cop = torch.tensor(scs.norm.cdf(X_train.reshape(-1,28*28)),dtype=torch.float32).clip(1e-5,1-1e-5)\n",
    "    \n",
    "    # training loop\n",
    "    igc_cop = IGC(hidden_size=100, layers_number=3, output_size=28*28)\n",
    "\n",
    "    u_obs = X_train_cop\n",
    "\n",
    "    optimizer = torch.optim.Adam(igc_cop.parameters())\n",
    "    loss_hist = []\n",
    "\n",
    "    for i in tqdm(range(1000)):\n",
    "        optimizer.zero_grad()\n",
    "        u = igc_cop.forward_train(torch.randn((200, igc_cop.dim_latent)))\n",
    "        loss = igc_cop.Energy_Score_pytorch(1, u_obs[np.random.choice(range(u_obs.shape[0]),100,replace=True)], u)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_hist.append(loss.item())\n",
    "        if i % 100 == 0:\n",
    "            print(loss.item())\n",
    "\n",
    "    samples_cdf = igc_cop.forward_train(torch.randn((25, igc_cop.dim_latent)))\n",
    "    print(seed)\n",
    "    print((W2(X_test.reshape(-1,28*28).float(),torch.tensor(scs.norm.ppf(samples_cdf.detach().numpy())).float(),),'IGC'))\n",
    "\n",
    "    torch.save(igc_cop.state_dict(), f'igc_cop_mnist_10runs_seed{seed}.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m samples_cdf \u001b[38;5;241m=\u001b[39m igc_cop\u001b[38;5;241m.\u001b[39mforward_train(torch\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m25\u001b[39m, igc_cop\u001b[38;5;241m.\u001b[39mdim_latent)))\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m((W2(\u001b[43mX_test\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat(),torch\u001b[38;5;241m.\u001b[39mtensor(scs\u001b[38;5;241m.\u001b[39mnorm\u001b[38;5;241m.\u001b[39mppf(samples_cdf\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()))\u001b[38;5;241m.\u001b[39mfloat(),),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIGC\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "samples_cdf = igc_cop.forward_train(torch.randn((25, igc_cop.dim_latent)))\n",
    "print((W2(X_test.reshape(-1,28*28).float(),torch.tensor(scs.norm.ppf(samples_cdf.detach().numpy())).float(),),'IGC'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36.019980000000004, 0.0648794697882153)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "IGC_MNIST_W2 = [\n",
    "    36.0713,\n",
    "    36.0503,\n",
    "    36.1236,\n",
    "    35.9470,\n",
    "    36.0018,\n",
    "    36.0666,\n",
    "    35.9763,\n",
    "    35.9971,\n",
    "    36.0689,\n",
    "    35.8969\n",
    "]\n",
    "np.mean(IGC_MNIST_W2), np.std(IGC_MNIST_W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182.99578218894004, 0.3859699447004303)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vine_MNIST_LL=[\n",
    "182.8999548028951,\n",
    "183.07594252548503,\n",
    "183.4142022677527,\n",
    "182.9113776227081,\n",
    "182.32917378065636,\n",
    "183.2038983816669,\n",
    "182.65361634253821,\n",
    "183.54003720756043,\n",
    "183.40584870213985,\n",
    "182.52377025599756]\n",
    "np.mean(vine_MNIST_LL), np.std(vine_MNIST_LL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
