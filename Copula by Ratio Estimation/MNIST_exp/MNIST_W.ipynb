{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import scipy.stats as scs\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.distributions as dist\n",
    "from pyhmc import hmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all mnist data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "np.random.seed(990109)\n",
    "torch.manual_seed(990109)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Lambda(lambda x: x.view(784))])\n",
    "trainset = datasets.MNIST(root='.', train=True, download=False, transform=transform)\n",
    "data_true = trainset.data.numpy()\n",
    "data_true = data_true.reshape(data_true.shape[0], -1)\n",
    "\n",
    "# Add Gaussian noise to dequentize\n",
    "noise = scs.norm.rvs(0, 0.05, data_true.shape)\n",
    "X_noisy_flat = (data_true + noise)\n",
    "\n",
    "# Apply ECDF transformation\n",
    "X_ecdf = np.zeros_like(X_noisy_flat)\n",
    "ecdf_list = []\n",
    "for dim in (range(X_noisy_flat.shape[1])):\n",
    "    ecdf = ECDF(X_noisy_flat[:, dim])\n",
    "    ecdf_list.append(ecdf)\n",
    "    X_ecdf[:, dim] = np.clip(ecdf(X_noisy_flat[:, dim]), 1e-6, 1 - 1e-6)\n",
    "\n",
    "\n",
    "# Apply inverse of standard normal CDF (ppf)\n",
    "X_gaussian = scs.norm.ppf(X_ecdf).reshape(-1, 28,28)\n",
    "y_gaussian = torch.ones(X_gaussian.shape[0], dtype=torch.long)\n",
    "# make it a tensor with shape (n_samples, n_channels, height, width)\n",
    "X_gaussian = torch.tensor(X_gaussian, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n",
    "\n",
    "# Split the data into training and testing sets (50/50 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_gaussian, y_gaussian, test_size=0.5, random_state=42)\n",
    "# Create TensorDataset objects\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "# Create DataLoader objects\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "def reverse_transform(example):\n",
    "    ''' \n",
    "    Reverse the transformation applied to the data using the ECDFs.\n",
    "    \n",
    "    input:\n",
    "        example: torch.Tensor - the transformed example, of shape (1, 28, 28)\n",
    "\n",
    "    output:\n",
    "        original_example: np.array - the original example, of shape (28, 28)\n",
    "    '''\n",
    "    # Convert the tensor to a numpy array and remove the channel dimension\n",
    "    example = example.squeeze().numpy().reshape(-1)\n",
    "    \n",
    "    # Apply the inverse of the standard normal CDF (ppf)\n",
    "    example = scs.norm.cdf(example)\n",
    "    \n",
    "    # Apply the inverse ECDF transformation\n",
    "    original_example = np.zeros_like(example)\n",
    "    for i in range(len(example)):\n",
    "        ecdf = ecdf_list[i]\n",
    "        original_example[i] = np.interp(example[i], ecdf.y, ecdf.x)\n",
    "    \n",
    "    # Reshape back to the original image shape and denormalize\n",
    "    original_example = original_example.reshape(28, 28) \n",
    "    \n",
    "    return original_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def waymark(data_p, data_q, alpha):\n",
    "\n",
    "    if not isinstance(data_p, torch.Tensor):\n",
    "        data_p = torch.tensor(data_p)\n",
    "    if not isinstance(data_q, torch.Tensor):\n",
    "        data_q = torch.tensor(data_q)\n",
    "    if not isinstance(alpha, torch.Tensor):\n",
    "        alpha = torch.tensor(alpha)\n",
    "\n",
    "    if data_p.shape[0] < data_q.shape[0]:\n",
    "        random_state = np.random.RandomState(42)\n",
    "        data_p_expand_ = data_p[random_state.choice(data_p.shape[0], data_q.shape[0]-data_p.shape[0], replace=True)]\n",
    "        data_p_expand = torch.concatenate([data_p_expand_, data_p])\n",
    "    else:  \n",
    "        data_p_expand = data_p\n",
    "    return torch.sqrt(1 - alpha) * data_p_expand + torch.sqrt(alpha) * data_q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 365220\n"
     ]
    }
   ],
   "source": [
    "# Define the ratio copula for MNIST data (28x28 images)\n",
    "class W_ratio_MNIST(nn.Module):\n",
    "    def __init__(self, in_shape=(1, 28, 28), normalising_cst=True, c=1.0, reg_lambda=1e-4, W_num=4):\n",
    "        super(W_ratio_MNIST, self).__init__()\n",
    "        self.normalising_cst = normalising_cst\n",
    "        self.reg_lambda = reg_lambda\n",
    "\n",
    "        if self.normalising_cst:\n",
    "            self.c = nn.ParameterList([nn.Parameter(torch.tensor(c)) for _ in range(W_num)])\n",
    "\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(28*28, 400),  # Adjusted for 28x28 input images\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(400, 100),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.heads = nn.ModuleList([nn.Linear(100, 1) for _ in range(W_num)])\n",
    "        self.W_num = W_num\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.reshape(-1, 28*28)\n",
    "        log_r = self.model(x)\n",
    "        out = 0\n",
    "        for w_idx,head in enumerate(self.heads):\n",
    "            if self.normalising_cst:\n",
    "                out += head(log_r) + self.c[w_idx].log()\n",
    "            else:\n",
    "                out += head(log_r)\n",
    "        return out\n",
    "    \n",
    "    def forward_train(self,x, w_idx):\n",
    "        x = x.reshape(-1, 28*28)\n",
    "        log_r = self.model(x)\n",
    "        if self.normalising_cst:\n",
    "            log_r = log_r + self.c[w_idx].log()\n",
    "        return self.heads[w_idx](log_r)\n",
    "\n",
    "    def regularizer_logr(self, logr_p, logr_q):\n",
    "        # Compute the L2 regularization term\n",
    "        return self.reg_lambda * (torch.sum(logr_p ** 2) + torch.sum(logr_q ** 2))\n",
    "\n",
    "\n",
    "# Calculate the number of parameters\n",
    "W_ratio = W_ratio_MNIST(W_num=10)\n",
    "\n",
    "total_params = sum(p.numel() for p in W_ratio.parameters())\n",
    "print(f'Total parameters: {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the ratio copula for MNIST data (28x28 images)\n",
    "class W_ratio_MNIST(nn.Module):\n",
    "    def __init__(self, in_shape=(1, 28, 28), normalising_cst=True, c=1.0, reg_lambda=1e-4, W_num=4):\n",
    "        super(W_ratio_MNIST, self).__init__()\n",
    "        self.normalising_cst = normalising_cst\n",
    "        self.reg_lambda = reg_lambda\n",
    "\n",
    "        if self.normalising_cst:\n",
    "            self.c = nn.ParameterList([nn.Parameter(torch.tensor(c)) for _ in range(W_num)])\n",
    "\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_shape[0], 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, 100),  # Adjusted for 28x28 input images\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.heads = nn.ModuleList([nn.Linear(100, 1) for _ in range(W_num)])\n",
    "        self.W_num = W_num\n",
    "\n",
    "    def forward(self,x):\n",
    "        log_r = self.model(x)\n",
    "        out = 0\n",
    "        for w_idx,head in enumerate(self.heads):\n",
    "            if self.normalising_cst:\n",
    "                out += head(log_r) + self.c[w_idx].log()\n",
    "            else:\n",
    "                out += head(log_r)\n",
    "        return out\n",
    "    \n",
    "    def forward_train(self,x, w_idx):\n",
    "        log_r = self.model(x)\n",
    "        if self.normalising_cst:\n",
    "            log_r = log_r + self.c[w_idx].log()\n",
    "        return self.heads[w_idx](log_r)\n",
    "\n",
    "    def regularizer_logr(self, logr_p, logr_q):\n",
    "        # Compute the L2 regularization term\n",
    "        return self.reg_lambda * (torch.sum(logr_p ** 2) + torch.sum(logr_q ** 2))\n",
    "\n",
    "\n",
    "#W_ratio.forward_train(torch.randn(1, 1, 28, 28),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 352288\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of parameters\n",
    "W_ratio = W_ratio_MNIST(W_num=10)\n",
    "\n",
    "total_params = sum(p.numel() for p in W_ratio.parameters())\n",
    "print(f'Total parameters: {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_nce_logsumexp(logr_p, logr_q,p_size, q_size):\n",
    "    v = q_size / p_size\n",
    "    # Compute log(v + r_p) and log(v + r_q) using logsumexp for numerical stability\n",
    "    log_v = torch.log(torch.tensor(v)) * torch.ones_like(logr_p)\n",
    "    log_v_plus_r_p = torch.logsumexp(torch.stack([log_v, logr_p]), dim=0)\n",
    "    log_v_plus_r_q = torch.logsumexp(torch.stack([log_v, logr_q]), dim=0)\n",
    "    # Compute the loss using the numerically stable logsumexp results\n",
    "    term1 = -(logr_p - log_v_plus_r_p).mean()\n",
    "    term2 = -v * (log_v - log_v_plus_r_q).mean()\n",
    "    \n",
    "    return term1 + term2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_GG_CNN.W_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:13<00:13, 13.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Loss: 0.32910600959880354, c: c[0]: 0.9403301477432251, c[1]: 1.0619312524795532, r_p: 15.395687103271484, r_q: -8.1253080368042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:26<00:00, 13.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2, Loss: 0.5314216039519308, c: c[0]: 0.9409188628196716, c[1]: 1.0901137590408325, r_p: 13.211756706237793, r_q: -8.948314666748047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def loss_nce(r_p, r_q,p_size, q_size):\n",
    "    v = q_size / p_size\n",
    "    return (-(r_p /(v+r_p)).log()).mean() - v* ((v/(v+r_q)).log().mean()) \n",
    "\n",
    "\n",
    "# Define model\n",
    "model_GG_CNN = W_ratio_MNIST(W_num=2,reg_lambda=1e-10)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "optimizer = optim.Adam(model_GG_CNN.parameters())#, lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "n_indep = 1\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 2\n",
    "\n",
    "GG_cov = np.cov(X_train.reshape(-1,28*28).T)\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model_GG_CNN.train()\n",
    "    running_loss = 0.0\n",
    "    noise_index = 0 \n",
    "\n",
    "    epoch_GG_noise = torch.tensor(scs.multivariate_normal.rvs(mean=np.zeros(28*28), cov=GG_cov, size=100*n_indep).reshape(-1,1,28,28)).float()\n",
    "    for inputs, labels in (train_loader):\n",
    "        for w_idx in range(model_GG_CNN.W_num):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            epoch_GG_noise_here = epoch_GG_noise[np.random.choice(epoch_GG_noise.shape[0], inputs.shape[0], replace=False)]\n",
    "            # 0 is data_p, 1 is data_q\n",
    "            data_p = waymark(inputs, epoch_GG_noise_here, w_idx/model_GG_CNN.W_num)\n",
    "            data_q = waymark(inputs, epoch_GG_noise_here, (w_idx+1)/model_GG_CNN.W_num)\n",
    "\n",
    "            r_p = model_GG_CNN.forward_train(data_p,w_idx).squeeze()\n",
    "            r_q = model_GG_CNN.forward_train(data_q,w_idx).squeeze()\n",
    "            noise_index += inputs.shape[0]\n",
    "            loss = loss_nce_logsumexp(r_p, r_q,data_p.shape[0], data_q.shape[0])\n",
    "            #loss += model_GG_CNN.regularizer_logr(r_p, r_q)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    if (epoch+1) % 1 == 0:\n",
    "        c_values = ', '.join([f\"c[{idx}]: {param.item()}\" for idx, param in enumerate(model_GG_CNN.c)])\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}, c: {c_values}, r_p: {r_p.mean().item()}, r_q: {r_q.mean().item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:02<00:00, 203.72it/s]\n",
      "100%|██████████| 469/469 [00:01<00:00, 275.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GG CNN ratio base train ; GG_ratio base test 37.930860546875 37.67798767089844\n",
      "GG CNN ratio corrected train ; GG_ratio corrected test 175.44310911458342 174.47730902506518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compute_logpdf_corrections(X, model, batch_size=64):\n",
    "    X_flat = X.reshape(-1, 28*28)\n",
    "    GG_cov = np.cov(X_flat.T)\n",
    "    GG_cov_tensor = torch.tensor(GG_cov, dtype=torch.float32)\n",
    "    multivariate_normal = dist.MultivariateNormal(loc=torch.zeros(28*28), covariance_matrix=GG_cov_tensor)\n",
    "    standard_normal = dist.Normal(loc=0, scale=1)\n",
    "\n",
    "    logpdf_multivariate_sum = 0\n",
    "    logpdf_standard_sum = 0\n",
    "    model_log_sum = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for i in tqdm(range(0, X.shape[0], batch_size)):\n",
    "        X_batch = X[i:i + batch_size]\n",
    "        X_batch_flat = X_batch.reshape(-1, 28*28)\n",
    "        logpdf_multivariate_sum += multivariate_normal.log_prob(X_batch_flat).sum().item()\n",
    "        logpdf_standard_sum += standard_normal.log_prob(X_batch_flat).sum(dim=1).sum().item()\n",
    "        model_log_sum += model(X_batch).sum().item()\n",
    "        total_samples += X_batch.shape[0]\n",
    "\n",
    "    avg_logpdf_multivariate = logpdf_multivariate_sum / total_samples\n",
    "    avg_logpdf_standard = logpdf_standard_sum / total_samples\n",
    "    avg_model_log = model_log_sum / total_samples\n",
    "\n",
    "    GG_correction = avg_logpdf_multivariate - avg_logpdf_standard\n",
    "    gg_CNN_ratio_corrected = GG_correction + avg_model_log\n",
    "\n",
    "    return gg_CNN_ratio_corrected,avg_model_log\n",
    "\n",
    "model_GG_CNN.eval()\n",
    "\n",
    "# Compute GG ratio corrected for train and test sets\n",
    "gg_CNN_ratio_corrected_train,gg_CNN_ratio_train = compute_logpdf_corrections(X_train, model_GG_CNN)\n",
    "gg_CNN_ratio_corrected_test, gg_CNN_ratio_test = compute_logpdf_corrections(X_test, model_GG_CNN)\n",
    "\n",
    "# Print the results\n",
    "print('GG CNN ratio base train ; GG_ratio base test', gg_CNN_ratio_train, gg_CNN_ratio_test)\n",
    "print('GG CNN ratio corrected train ; GG_ratio corrected test', gg_CNN_ratio_corrected_train, gg_CNN_ratio_corrected_test)\n",
    "\n",
    "# test1 GG CNN ratio corrected train ; GG_ratio corrected test 180.250578092448 179.32892821451833\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:43<00:00, 20.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 784)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# HMC\n",
    "\n",
    "def sample_GG_hmc(GG_ratio_model, num_samples, num_runs_hmc, num_burnin):\n",
    "    ''' \n",
    "    Sample from the ratio model with HMC.\n",
    "    \n",
    "    args:\n",
    "        GG_ratio_model: nn.Module - the GG ratio copula model\n",
    "        num_samples: int - the number of samples to generate per HMC run\n",
    "        num_runs_hmc: int - the number of HMC runs, each giving num_samples draws\n",
    "        num_burnin: int - the number of burn-in steps for a single HMC run\n",
    "    \n",
    "    returns:\n",
    "        samples,log_pdf with\n",
    "        samples: np.array - the generated samples of shape (num_runs_hmc*num_samples, 64)\n",
    "        log_pdf: np.array - the log-pdf of the samples of shape (num_runs_hmc*num_samples,)\n",
    "    '''\n",
    "    GG_ratio_model.eval()\n",
    "    def log_GGratio_gauss(x):\n",
    "        ''' \n",
    "        Compute the log-pdf of the GG_ratio copula model and its gradient at x. \n",
    "        Takes the ratio model and adjusts it by the GG factor to make it into a copula.\n",
    "        '''\n",
    "        # compute the top part of a GG_ratio copula logpdf and the gradients of that\n",
    "        x_tensor = torch.tensor(x.reshape(1, 1, 28, 28), dtype=torch.float32, requires_grad=True)\n",
    "        x_flat = x_tensor.reshape(-1, 28*28)\n",
    "        # define N(Sigma) and N(0,1), then compute on x\n",
    "        GG_cov_tensor = torch.tensor(GG_cov, dtype=torch.float32)\n",
    "        multivariate_normal = dist.MultivariateNormal(loc=torch.zeros(28*28), covariance_matrix=GG_cov_tensor+torch.eye(GG_cov_tensor.size(0))*1e-6)\n",
    "        standard_normal = dist.Normal(loc=0, scale=1)\n",
    "        logpdf_multivariate = multivariate_normal.log_prob(x_flat)\n",
    "        logpdf_standard = standard_normal.log_prob(x_flat).sum(dim=1)\n",
    "        gg_correction = logpdf_multivariate - logpdf_standard\n",
    "        # Compute the log of the ratio model\n",
    "        log_ratio = (GG_ratio_model(x_tensor)).sum()\n",
    "        # Compute the log probability of x under the standard normal distribution\n",
    "        log_prob_standard = standard_normal.log_prob(x_tensor).sum()\n",
    "        # Compute the final function value\n",
    "        fun = log_ratio + gg_correction + log_prob_standard\n",
    "        # Backward pass to compute the gradient\n",
    "        fun.backward()\n",
    "        grad_wrt_x = x_tensor.grad.reshape(1, -1)[0]\n",
    "        \n",
    "        return np.array(fun.item(), dtype=np.float64), np.array(grad_wrt_x.detach().numpy(), dtype=np.float64)\n",
    "\n",
    "    samples = np.zeros((num_runs_hmc, num_samples, 28*28))\n",
    "    log_pdf = np.zeros((num_runs_hmc, num_samples))\n",
    "    x0_noise = np.zeros((num_runs_hmc, 28, 28))\n",
    "    for hmc_run in tqdm( range(num_runs_hmc)):\n",
    "\n",
    "        '''# pick x0 with highest r(x0) from random noise\n",
    "        x0_proposal = torch.randn(1000, 1, 28, 28)\n",
    "        r_noise = model(x0_proposal)\n",
    "        x0_run = x0_proposal[np.argmax(r_noise.detach().numpy().flatten())]    \n",
    "        '''\n",
    "        '''\n",
    "        # pick x0 randomly from N(0,1) \n",
    "        x0_run = torch.randn(1, 1, 28, 28)\n",
    "        '''\n",
    "        '''\n",
    "        # IS from GG\n",
    "        GG_cov = np.cov(X_train.reshape(-1,28*28).T)\n",
    "        x0_run_np = scs.multivariate_normal.rvs(mean=np.zeros(28*28), cov=GG_cov, size=10).reshape(-1,1,28,28)\n",
    "        x0_run = torch.tensor(x0_run_np, dtype=torch.float32)\n",
    "        r_noise = GG_ratio_model(x0_run.reshape(-1,1,28,28))\n",
    "        log_probs = torch.logsumexp(r_noise, dim=0)# Compute logsumexp normalized probabilities\n",
    "        probs = torch.exp(r_noise - log_probs)\n",
    "        x0_run = x0_run[np.random.choice(x0_run.shape[0], 1, replace=False, p = probs.detach().numpy().flatten())]\n",
    "        '''\n",
    "        GG_cov = np.cov(X_train.reshape(-1,28*28).T)\n",
    "        x0_run_np = scs.multivariate_normal.rvs(mean=np.zeros(28*28), cov=GG_cov, size=1).reshape(1,1,28,28)\n",
    "        x0_run = torch.tensor(x0_run_np, dtype=torch.float32)\n",
    "        samples_, log_pdf_ = hmc(log_GGratio_gauss,\n",
    "                            x0=x0_run.flatten().numpy(),\n",
    "                            n_samples=num_samples,\n",
    "                            return_logp=True,\n",
    "                            n_burn=num_burnin)\n",
    "        \n",
    "        samples[hmc_run] = samples_\n",
    "        log_pdf[hmc_run] = log_pdf_\n",
    "        x0_noise[hmc_run] = x0_run\n",
    "\n",
    "    return samples.reshape(-1,28*28), log_pdf.reshape(-1), x0_noise\n",
    "\n",
    "sample_GG_CNN, log_pdf, x0_noises = sample_GG_hmc(GG_ratio_model=model_GG_CNN, \n",
    "                            num_samples=1, \n",
    "                            num_runs_hmc=5,\n",
    "                            num_burnin=500)\n",
    "print(sample_GG_CNN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 58.45it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 50.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[685.21899414 808.27392578 535.12286377 417.66949463 656.45684814]\n",
      "[276.07888794 142.88230896 243.56567383 121.20240021 184.04104614]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def log_GGratio_gauss(GG_ratio_model,x):\n",
    "        ''' \n",
    "        Compute the log-pdf of the GG_ratio copula model and its gradient at x. \n",
    "        Takes the ratio model and adjusts it by the GG factor to make it into a copula.\n",
    "        '''\n",
    "        # compute the top part of a GG_ratio copula logpdf and the gradients of that\n",
    "        x_tensor = x.reshape(1, 1, 28, 28)\n",
    "        x_flat = x_tensor.reshape(-1, 28*28)\n",
    "        # define N(Sigma) and N(0,1), then compute on x\n",
    "        GG_cov_tensor = torch.tensor(GG_cov, dtype=torch.float32)\n",
    "        multivariate_normal = dist.MultivariateNormal(loc=torch.zeros(28*28), covariance_matrix=GG_cov_tensor+torch.eye(GG_cov_tensor.size(0))*1e-6)\n",
    "        standard_normal = dist.Normal(loc=0, scale=1)\n",
    "        logpdf_multivariate = multivariate_normal.log_prob(x_flat)\n",
    "        logpdf_standard = standard_normal.log_prob(x_flat).sum(dim=1)\n",
    "        gg_correction = logpdf_multivariate - logpdf_standard\n",
    "        # Compute the log of the ratio model\n",
    "        log_ratio = (GG_ratio_model(x_tensor)).sum()\n",
    "        # Compute the log probability of x under the standard normal distribution\n",
    "        log_prob_standard = standard_normal.log_prob(x_tensor).sum()\n",
    "        # Compute the final function value\n",
    "        fun = log_ratio + gg_correction #+ log_prob_standard\n",
    "        \n",
    "        return fun.item()\n",
    "\n",
    "sample_pdf = np.array([log_GGratio_gauss(model_GG_CNN,torch.tensor(sample_GG_CNN[k]).float().reshape(-1,1,28,28)) for k in tqdm(range(5))]\n",
    ")\n",
    "sample_pdf #array([129.77880859, 110.35611725, 179.03207397, 127.83757019,125.4307251 ]) with 1k burnin\n",
    "x0_pdf = np.array([log_GGratio_gauss(model_GG_CNN,torch.tensor(x0_noises[k]).float().reshape(-1,1,28,28)) for k in tqdm(range(5))])\n",
    "print(sample_pdf)\n",
    "print(x0_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x432 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Assuming reverse_transform, sample_GG_CNN, and x0_noises are already defined\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "fig.suptitle(\"500 buring hmc N01\", fontsize=16)\n",
    "\n",
    "for i in range(5):\n",
    "    # Top row: true samples\n",
    "    axes[0, i].imshow(reverse_transform(torch.tensor(sample_GG_CNN[i])).reshape(28, 28), cmap='gray')\n",
    "    axes[0, i].axis('off')\n",
    "    axes[0, i].set_title(f'Sample {i+1} logpdf:'+str(int(sample_pdf[i])))\n",
    "\n",
    "    # Bottom row: x0 points\n",
    "    axes[1, i].imshow(reverse_transform(torch.tensor(x0_noises[i])).reshape(28, 28), cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "    axes[1, i].set_title(f'x0 {i+1} logpdf:'+str(int(x0_pdf[i])))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
