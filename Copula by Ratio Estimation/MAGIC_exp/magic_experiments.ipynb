{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NNet Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Ratio\n",
    "import sys\n",
    "import os\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.append(parent_dir)\n",
    "from Ratio import *\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torch.distributions as dist\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import scipy.stats as scs\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import time\n",
    "import ot\n",
    "from pyhmc import hmc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAGIC_data = pd.read_csv('magic.csv')\n",
    "MAGIC_data = np.array(MAGIC_data.iloc[:,:-1])\n",
    "torch.manual_seed(990109)\n",
    "np.random.seed(990109)\n",
    "\n",
    "seed = 990109\n",
    "\n",
    "n_indep = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply ECDF transformation\n",
    "X_ecdf = np.zeros_like(MAGIC_data)\n",
    "ecdf_list = []\n",
    "for dim in range((MAGIC_data.shape[1])):\n",
    "    ecdf = ECDF(MAGIC_data[:, dim])\n",
    "    ecdf_list.append(ecdf)\n",
    "    X_ecdf[:, dim] = np.clip(ecdf(MAGIC_data[:, dim]), 1e-6, 1 - 1e-6)\n",
    "\n",
    "# Apply inverse of standard normal CDF (ppf)\n",
    "X_gaussian = scs.norm.ppf(X_ecdf)\n",
    "y_gaussian = torch.ones(X_gaussian.shape[0], dtype=torch.long)\n",
    "# Convert to PyTorch tensors\n",
    "X_gaussian = torch.tensor(X_gaussian, dtype=torch.float32)\n",
    "# Split the data into training and testing sets (50/50 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_gaussian, y_gaussian, test_size=0.5, random_state=seed)\n",
    "# Create TensorDataset objects\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "# Create DataLoader objects\n",
    "train_loader = DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=200, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19020"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAGIC_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 10/51 [00:07<00:30,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/51, Loss: 1.727375956873099, c: 0.992900550365448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 20/51 [00:14<00:23,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/51, Loss: 1.5674748544891675, c: 0.98805171251297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 30/51 [00:22<00:16,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/51, Loss: 1.4926831449071567, c: 0.9842197895050049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 40/51 [00:29<00:08,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/51, Loss: 1.4362997983892758, c: 0.9797634482383728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 50/51 [00:36<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/51, Loss: 1.4071091040968895, c: 0.9773656129837036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:37<00:00,  1.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ratio(\n",
       "  (fc_in): Linear(in_features=10, out_features=100, bias=True)\n",
       "  (fc_hidden): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc_out): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratio_model = True\n",
    "\n",
    "\n",
    "\n",
    "if train_ratio_model:\n",
    "    # Define model\n",
    "    ratio_model = Ratio(h_dim=100, in_dim=10, h_layers=2, normalising_cst = True, c = 1.0)\n",
    "\n",
    "    # training loop for ####  GG Ratio  ####\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    optimizer = torch.optim.Adam(\n",
    "            [{'params': [param for param in ratio_model.parameters() if param is not ratio_model.c]},\n",
    "            {'params': [ratio_model.c], 'lr': 0.001}]  # Adjust the learning rate for ratio.c here\n",
    "        )\n",
    "\n",
    "    num_epochs = 51\n",
    "\n",
    "    GG_cov = np.cov(X_train.reshape(-1,10).T)\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        ratio_model.train()\n",
    "        running_loss = 0.0\n",
    "        noise_index = 0 \n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            r_p = ratio_model(inputs).squeeze()\n",
    "            r_q = ratio_model(torch.tensor(scs.multivariate_normal.rvs(mean=np.zeros(10), cov=GG_cov, size=n_indep*inputs.shape[0])).float()).squeeze()\n",
    "            noise_index += inputs.shape[0]\n",
    "            loss = loss_nce(r_p, r_q,inputs.shape[0], n_indep*inputs.shape[0])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}, c: {ratio_model.c.item()}\")\n",
    "    # save the model\n",
    "    #filename = f'GGNNet_{n_indep}_digits_seed_{seed}.pth'\n",
    "    #torch.save(ratio_model.state_dict(), filename)\n",
    "\n",
    "else: # load the pre-trained model\n",
    "    filename = f'GGNNet_{n_indep}_digits_seed_{seed}.pth'\n",
    "    ratio_model = Ratio_Simple()\n",
    "    ratio_model.load_state_dict(torch.load(filename))\n",
    "\n",
    "ratio_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GG ratio alone 2.659236431121826 2.4405224323272705\n",
      "GG ratio corrected ; GG_ratio full 6.6446661949157715 6.447673797607422\n"
     ]
    }
   ],
   "source": [
    "# LL computation\n",
    "\n",
    "ratio_model.eval()\n",
    "X_train_flat = X_train.reshape(-1, 10)\n",
    "X_test_flat = X_test.reshape(-1, 10)\n",
    "GG_cov = np.cov(X_train_flat.T)\n",
    "# Define the multivariate normal distribution with the given covariance matrix\n",
    "GG_cov_tensor = torch.tensor(GG_cov, dtype=torch.float32)\n",
    "multivariate_normal = dist.MultivariateNormal(loc=torch.zeros(10), covariance_matrix=GG_cov_tensor)\n",
    "# Define the standard normal distribution\n",
    "standard_normal = dist.Normal(loc=0, scale=1)\n",
    "# Compute logpdf for the multivariate normal distribution\n",
    "logpdf_multivariate_train = multivariate_normal.log_prob(X_train_flat)\n",
    "logpdf_multivariate_test = multivariate_normal.log_prob(X_test_flat)\n",
    "# Compute logpdf for the standard normal distribution and sum over the dimensions\n",
    "logpdf_standard_train = standard_normal.log_prob(X_train_flat).sum(dim=1)\n",
    "logpdf_standard_test = standard_normal.log_prob(X_test_flat).sum(dim=1)\n",
    "# Compute GG_correction\n",
    "GG_correction_train = logpdf_multivariate_train - logpdf_standard_train\n",
    "GG_correction_test = logpdf_multivariate_test - logpdf_standard_test\n",
    "# Compute means\n",
    "mean_GG_correction_train = GG_correction_train.mean()\n",
    "mean_GG_correction_test = GG_correction_test.mean()\n",
    "\n",
    "# Compute GG ratio alone\n",
    "gg_ratio_train = ratio_model(X_train).log().mean()\n",
    "gg_ratio_test = ratio_model(X_test).log().mean()\n",
    "\n",
    "# Compute GG ratio corrected\n",
    "gg_ratio_corrected_train = (GG_correction_train + ratio_model(X_train).log()).mean()\n",
    "gg_ratio_corrected_test = (GG_correction_test + ratio_model(X_test).log()).mean()\n",
    "\n",
    "# Print the results\n",
    "print('GG ratio alone', gg_ratio_train.item(), gg_ratio_test.item())\n",
    "print('GG ratio corrected ; GG_ratio full', gg_ratio_corrected_train.item(), gg_ratio_corrected_test.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:25<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 10)\n",
      "tensor(1.9952) GG+Netratio 100hmc\n",
      "tensor(2.1060) true obs\n",
      "tensor(2.3026) gaussian\n",
      "tensor(2.9598) random\n",
      "(10, 990109, True)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'start' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 95\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mprint\u001b[39m(W2(X_test\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat(),torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m500\u001b[39m,\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()[:\u001b[38;5;241m50\u001b[39m]),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28mprint\u001b[39m((n_indep,seed,train_ratio_model))\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime:\u001b[39m\u001b[38;5;124m'\u001b[39m, time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39m\u001b[43mstart\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'start' is not defined"
     ]
    }
   ],
   "source": [
    "import scipy.stats as scs\n",
    "# HMC\n",
    "\n",
    "def sample_GG_hmc(GG_ratio_model, num_samples, num_runs_hmc, num_burnin):\n",
    "    ''' \n",
    "    Sample from the ratio model with HMC.\n",
    "    \n",
    "    args:\n",
    "        GG_ratio_model: nn.Module - the GG ratio copula model\n",
    "        num_samples: int - the number of samples to generate per HMC run\n",
    "        num_runs_hmc: int - the number of HMC runs, each giving num_samples draws\n",
    "        num_burnin: int - the number of burn-in steps for a single HMC run\n",
    "    \n",
    "    returns:\n",
    "        samples,log_pdf with\n",
    "        samples: np.array - the generated samples of shape (num_runs_hmc*num_samples, 10)\n",
    "        log_pdf: np.array - the log-pdf of the samples of shape (num_runs_hmc*num_samples,)\n",
    "    '''\n",
    "    GG_ratio_model.eval()\n",
    "    def log_GGratio_gauss(x):\n",
    "        ''' \n",
    "        Compute the log-pdf of the GG_ratio copula model and its gradient at x. \n",
    "        Takes the ratio model and adjusts it by the GG factor to make it into a copula.\n",
    "        '''\n",
    "        # compute the top part of a GG_ratio copula logpdf and the gradients of that\n",
    "        x_tensor = torch.tensor(x, dtype=torch.float32, requires_grad=True)\n",
    "        x_flat = x_tensor.reshape(-1, 10)\n",
    "        # define N(Sigma) and N(0,1), then compute on x\n",
    "        GG_cov_tensor = torch.tensor(GG_cov, dtype=torch.float32)\n",
    "        multivariate_normal = dist.MultivariateNormal(loc=torch.zeros(10), covariance_matrix=GG_cov_tensor)\n",
    "        standard_normal = dist.Normal(loc=0, scale=1)\n",
    "        logpdf_multivariate = multivariate_normal.log_prob(x_flat)\n",
    "        logpdf_standard = standard_normal.log_prob(x_flat).sum(dim=1)\n",
    "        gg_correction = logpdf_multivariate - logpdf_standard\n",
    "        # Compute the log of the ratio model\n",
    "        log_ratio = torch.log(GG_ratio_model(x_tensor)).sum()\n",
    "        # Compute the log probability of x under the standard normal distribution\n",
    "        log_prob_standard = standard_normal.log_prob(x_tensor).sum()\n",
    "        # Compute the final function value\n",
    "        fun = log_ratio + gg_correction + log_prob_standard\n",
    "        # Backward pass to compute the gradient\n",
    "        fun.backward()\n",
    "        grad_wrt_x = x_tensor.grad.reshape(1, -1)[0]\n",
    "        \n",
    "        return np.array(fun.item(), dtype=np.float64), np.array(grad_wrt_x.detach().numpy(), dtype=np.float64)\n",
    "\n",
    "    samples = np.zeros((num_runs_hmc, num_samples, 10))\n",
    "    log_pdf = np.zeros((num_runs_hmc, num_samples))\n",
    "    x0_noise = np.zeros((num_runs_hmc,10))\n",
    "    for hmc_run in tqdm( range(num_runs_hmc)):\n",
    "\n",
    "        '''# pick x0 with highest r(x0) from random noise\n",
    "        x0_proposal = torch.randn(1000, 1, 8, 8)\n",
    "        r_noise = model(x0_proposal)\n",
    "        x0_run = x0_proposal[np.argmax(r_noise.detach().numpy().flatten())]    \n",
    "        '''\n",
    "        # pick x0 randomly from N(0,1) \n",
    "        x0_run = torch.randn(1, 10)\n",
    "        '''GG_cov = np.cov(X_train.reshape(-1,10).T)\n",
    "        x0_run_np = scs.multivariate_normal.rvs(mean=np.zeros(10), cov=GG_cov, size=1).reshape(1,1,8,8)\n",
    "        x0_run = torch.tensor(x0_run_np, dtype=torch.float32)'''\n",
    "        samples_, log_pdf_ = hmc(log_GGratio_gauss,\n",
    "                            x0=x0_run.flatten().numpy(),\n",
    "                            n_samples=num_samples,\n",
    "                            return_logp=True,\n",
    "                            n_burn=num_burnin)\n",
    "        \n",
    "        samples[hmc_run] = samples_\n",
    "        log_pdf[hmc_run] = log_pdf_\n",
    "        x0_noise[hmc_run] = x0_run\n",
    "\n",
    "    return samples.reshape(-1,10), log_pdf.reshape(-1), x0_noise\n",
    "\n",
    "samples_simpleGG, log_pdf, x0_noises = sample_GG_hmc(GG_ratio_model=ratio_model, \n",
    "                            num_samples=1, \n",
    "                            num_runs_hmc=50,\n",
    "                            num_burnin=100)\n",
    "print(samples_simpleGG.shape)\n",
    "\n",
    "# Save the samples and log probabilities\n",
    "#np.save(f'GGNNet_HM100burnin_N01_{n_indep}_{seed}_samples_digits.npy', samples_simpleGG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.00135562, 0.01057385, 0.06290086, 0.20212326, 0.36574685,\n",
       "        0.36710248, 0.20008983, 0.06642547, 0.01152279, 0.00135562]),\n",
       " array([-3.87838435, -3.10270739, -2.32703066, -1.55135369, -0.77567685,\n",
       "         0.        ,  0.77567685,  1.55135369,  2.32703066,  3.10270739,\n",
       "         3.87838435]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(samples_simpleGG[:,0],density=True)\n",
    "plt.hist(X_train[:,0].numpy(), alpha=0.5, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9952) GG+Netratio 100hmc\n",
      "tensor(2.1060) true obs\n",
      "tensor(2.2983) gaussian\n",
      "tensor(2.9949) random\n",
      "(10, 990109, True)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'start' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(W2(X_test\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat(),torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m500\u001b[39m,\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()[:\u001b[38;5;241m50\u001b[39m]),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m((n_indep,seed,train_ratio_model))\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime:\u001b[39m\u001b[38;5;124m'\u001b[39m, time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39m\u001b[43mstart\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'start' is not defined"
     ]
    }
   ],
   "source": [
    "# assess sample quality\n",
    "\n",
    "def W2(x,y):\n",
    "    return torch.sqrt(ot.emd2(torch.ones(x.shape[0])/x.shape[0], torch.ones(y.shape[0])/y.shape[0], ot.dist(x, y)))\n",
    "\n",
    "print(W2(X_test.reshape(-1,10).float(),torch.tensor(samples_simpleGG).float()),'GG+Netratio 100hmc') \n",
    "print(W2(X_test.reshape(-1,10).float(),X_train.reshape(-1,10).float()[:50]),'true obs')\n",
    "print(W2(X_test.reshape(-1,10).float(),torch.tensor(scs.multivariate_normal.rvs(mean=np.zeros(10), cov=GG_cov, size=500)).float()[:50]),'gaussian')\n",
    "print(W2(X_test.reshape(-1,10).float(),torch.randn(500,10).float()[:50]),'random')\n",
    "\n",
    "print((n_indep,seed,train_ratio_model))\n",
    "\n",
    "print('Time:', time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IGC vine and Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torch.distributions as dist\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import scipy.stats as scs\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import time\n",
    "import ot\n",
    "from pyhmc import hmc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as scs\n",
    "from tqdm import tqdm\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import pyvinecopulib as pv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_nce(r_p, r_q,p_size, q_size):\n",
    "    v = q_size / p_size\n",
    "    return (-(r_p /(v+r_p)).log()).mean() - v* ((v/(v+r_q)).log().mean()) \n",
    "\n",
    "def W2(x,y):\n",
    "    return torch.sqrt(ot.emd2(torch.ones(x.shape[0])/x.shape[0], torch.ones(y.shape[0])/y.shape[0], ot.dist(x, y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAGIC_data = pd.read_csv('magic.csv')\n",
    "MAGIC_data = np.array(MAGIC_data.iloc[:,:-1])\n",
    "torch.manual_seed(990109)\n",
    "np.random.seed(990109)\n",
    "\n",
    "seed = 990109\n",
    "\n",
    "n_indep = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply ECDF transformation\n",
    "X_ecdf = np.zeros_like(MAGIC_data)\n",
    "ecdf_list = []\n",
    "for dim in range((MAGIC_data.shape[1])):\n",
    "    ecdf = ECDF(MAGIC_data[:, dim])\n",
    "    ecdf_list.append(ecdf)\n",
    "    X_ecdf[:, dim] = np.clip(ecdf(MAGIC_data[:, dim]), 1e-6, 1 - 1e-6)\n",
    "\n",
    "# Apply inverse of standard normal CDF (ppf)\n",
    "X_gaussian = scs.norm.ppf(X_ecdf)\n",
    "y_gaussian = torch.ones(X_gaussian.shape[0], dtype=torch.long)\n",
    "# Convert to PyTorch tensors\n",
    "X_gaussian = torch.tensor(X_gaussian, dtype=torch.float32)\n",
    "# Split the data into training and testing sets (50/50 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_gaussian, y_gaussian, test_size=0.5, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SoftRank(nn.Module):\n",
    "    \"\"\"Differentiable ranking layer\"\"\"\n",
    "    def __init__(self, alpha=1000.0):\n",
    "        super(SoftRank, self).__init__()\n",
    "        self.alpha = alpha # constant for scaling the sigmoid to approximate sign function, larger values ensure better ranking, overflow is handled properly by PyTorch\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # input is a ?xSxD tensor, we wish to rank the S samples in each dimension per each batch\n",
    "        # output is  ?xSxD tensor where for each dimension the entries are (rank-0.5)/N_rank\n",
    "        x = inputs.unsqueeze(-1) #(?,S,D) -> (?,S,D,1)\n",
    "        x_2 = x.repeat(1, 1, 1, x.shape[1]) # (?,S,D,1) -> (?,S,D,S) (samples are repeated along axis 3, i.e. the last axis)\n",
    "        x_1 = x_2.transpose(1, 3) #  (?,S,D,S) -> (?,S,D,S) (samples are repeated along axis 1)\n",
    "        return torch.transpose(torch.sum(torch.sigmoid(self.alpha*(x_1-x_2)), dim=1), 1, 2)/(torch.tensor(x.shape[1], dtype=torch.float32))\n",
    "\n",
    "\n",
    "class IGC(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size=100, layers_number=2, output_size=2):\n",
    "        super(IGC, self).__init__()\n",
    "        self.dim_latent = 3 * output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers_nuber = layers_number\n",
    "        self.output_size = output_size\n",
    "        self.linear_in = nn.Linear(in_features=self.dim_latent, out_features=self.hidden_size) \n",
    "        self.linear = nn.Linear(in_features=self.hidden_size, out_features=self.hidden_size)\n",
    "        self.linear_out = nn.Linear(in_features=self.hidden_size, out_features=self.output_size)\n",
    "        self.marginal_cdfs = None\n",
    "        self.ecdf_10e6_samples = None\n",
    "\n",
    "    def forward_train(self, z):\n",
    "        '''\n",
    "        Input noise z with shape (M,dim_latent)\\\\\n",
    "        Outputs (u,v) pairs with shape (M,output_size=2), while ensuring u and v each have uniform marginals.\n",
    "        '''\n",
    "        y = torch.relu(self.linear_in(z))\n",
    "        for layer in range(self.layers_nuber):\n",
    "            y = torch.relu(self.linear(y))\n",
    "        y = self.linear_out(y).unsqueeze(0)\n",
    "        u = SoftRank()(y).squeeze(0)\n",
    "        return u\n",
    "        \n",
    "    def Energy_Score_pytorch(self,beta, observations_y, simulations_Y):\n",
    "        n = len(observations_y)\n",
    "        m = len(simulations_Y)\n",
    "\n",
    "        # First part |Y-y|. Gives the L2 dist scaled by power beta. Is a vector of length n/one value per location.\n",
    "        diff_Y_y = torch.pow(\n",
    "            torch.norm(\n",
    "                (observations_y.unsqueeze(1) -\n",
    "                simulations_Y.unsqueeze(0)).float(),\n",
    "                dim=2,keepdim=True).reshape(-1,1),\n",
    "            beta)\n",
    "\n",
    "        # Second part |Y-Y'|. 2* because pdist counts only once.\n",
    "        diff_Y_Y = 2 * torch.pow(\n",
    "            nn.functional.pdist(simulations_Y),\n",
    "            beta)\n",
    "        Energy = 2 * torch.mean(diff_Y_y) - torch.sum(diff_Y_Y) / (m * (m - 1))\n",
    "        return Energy\n",
    "\n",
    "\n",
    "    def forward(self, n_samples):\n",
    "        ''' \n",
    "        Function to sample from the copula, once training is done.\n",
    "\n",
    "        Input: n_samples - number of samples to generate\n",
    "        Output: torch.tensor of shape (n_samples, output_size) on copula space.\n",
    "        '''\n",
    "        with torch.no_grad():\n",
    "            if self.marginal_cdfs is None:\n",
    "                self.marginal_cdfs = []\n",
    "                # sample 10^6 points from the latent space and compute empirical marginal cdfs\n",
    "                z = torch.randn(10**6, self.dim_latent)\n",
    "                y = torch.relu(self.linear_in(z))\n",
    "                for layer in range(self.layers_nuber):\n",
    "                    y = torch.relu(self.linear(y))\n",
    "                y = self.linear_out(y) # samples used to approximate cdfs\n",
    "                for dim in range(y.shape[1]):\n",
    "                    ecdf = ECDF(y[:, dim].numpy())\n",
    "                    self.marginal_cdfs.append(ecdf)\n",
    "                self.ecdf_10e6_samples = y\n",
    "            # sample the latent space and apply ecdfs\n",
    "            z = torch.randn(n_samples, self.dim_latent)\n",
    "            y = torch.relu(self.linear_in(z))\n",
    "            for layer in range(self.layers_nuber):\n",
    "                y = torch.relu(self.linear(y))\n",
    "            y = self.linear_out(y)\n",
    "            for dim in range(y.shape[1]):\n",
    "                y[:, dim] = torch.tensor(self.marginal_cdfs[dim](y[:, dim].numpy()), dtype=torch.float32)\n",
    "            return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make training data on 0-1 scale\n",
    "X_train_cop = torch.tensor(scs.norm.cdf(X_train.reshape(-1,10)),dtype=torch.float32).clip(1e-5,1-1e-5)\n",
    "\n",
    "# training loop\n",
    "igc_cop = IGC(hidden_size=100, layers_number=2, output_size=10)\n",
    "\n",
    "u_obs = X_train_cop\n",
    "\n",
    "optimizer = torch.optim.Adam(igc_cop.parameters())\n",
    "loss_hist = []\n",
    "\n",
    "for i in tqdm(range(501)):\n",
    "    optimizer.zero_grad()\n",
    "    u = igc_cop.forward_train(torch.randn((200, igc_cop.dim_latent)))\n",
    "    loss = igc_cop.Energy_Score_pytorch(1, u_obs[np.random.choice(range(u_obs.shape[0]),100,replace=True)], u)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_hist.append(loss.item())\n",
    "\n",
    "# save the model\n",
    "torch.save(igc_cop.state_dict(), f'igc_cop{seed}.pth')\n",
    "# sample\n",
    "samples_cdf = igc_cop.forward(500).detach().numpy()\n",
    "# save the samples\n",
    "np.save(f'samples_igc{seed}.npy',samples_cdf)\n",
    "print((W2(X_test.reshape(-1,64).float(),torch.tensor(scs.norm.ppf(samples_cdf)).float(),),'IGC'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
